import { NextRequest, NextResponse } from 'next/server'
import { createClient } from '@supabase/supabase-js'
import OpenAI from 'openai'

// Inicjalizacja klientÃ³w
const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!,
  {
    db: { schema: 'public' },
    global: { headers: { 'x-my-custom-header': 'no-cache' } },
  }
)

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

// Funkcja do dzielenia tekstu na chunki
function splitIntoChunks(text: string, chunkSize: number = 1000, overlap: number = 200): string[] {
  const chunks: string[] = []
  let start = 0

  // Walidacja: overlap musi byÄ‡ mniejszy niÅ¼ chunkSize
  const safeOverlap = Math.min(overlap, chunkSize - 1)

  while (start < text.length) {
    const end = Math.min(start + chunkSize, text.length)
    chunks.push(text.slice(start, end))

    // PrzesuÅ„ start o (chunkSize - overlap)
    start += chunkSize - safeOverlap

    // BezpieczeÅ„stwo: jeÅ›li start siÄ™ nie zmienia, przerwij
    if (start <= end - chunkSize + safeOverlap && chunks.length > 1000) {
      console.error('âš ï¸ NieskoÅ„czona pÄ™tla w splitIntoChunks!')
      break
    }
  }

  return chunks
}

// Funkcja do tworzenia embeddings z OpenAI
async function createEmbedding(text: string): Promise<number[]> {
  try {
    // Ogranicz dÅ‚ugoÅ›Ä‡ tekstu do 8191 tokenÃ³w (limit OpenAI)
    const truncatedText = text.slice(0, 8000)

    const response = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: truncatedText,
    })

    const embedding = response.data[0].embedding
    console.log(`âœ… Embedding utworzony (wymiary: ${embedding.length})`)
    return embedding
  } catch (error: any) {
    console.error('âŒ BÅ‚Ä…d tworzenia embeddings:', error.message)
    throw new Error(`BÅ‚Ä…d OpenAI embeddings: ${error.message}`)
  }
}

export async function POST(req: NextRequest) {
  try {
    console.log('ğŸ“¥ Otrzymano request...')
    const body = await req.json()
    console.log('ğŸ“¦ Body keys:', Object.keys(body))

    const { manualText, manualName } = body

    if (!manualText || !manualName) {
      console.log('âŒ Brak wymaganych pÃ³l')
      return NextResponse.json(
        { error: 'Brak tekstu lub nazwy manuala' },
        { status: 400 }
      )
    }

    console.log(`ğŸ“„ Przetwarzanie manuala: ${manualName}`)
    console.log(`ğŸ“ DÅ‚ugoÅ›Ä‡ tekstu: ${manualText.length} znakÃ³w`)
    console.log(`ğŸ“ Typ manualText: ${typeof manualText}`)

    // Podziel na chunki
    const chunks = splitIntoChunks(manualText, 1000, 200)
    console.log(`âœ‚ï¸ Podzielono na ${chunks.length} chunkÃ³w`)

    // UsuÅ„ stare wpisy dla tego manuala
    const { error: deleteError } = await supabase
      .from('manuals_documents')
      .delete()
      .eq('manual_name', manualName)

    if (deleteError) {
      console.log('Info: Nie znaleziono starych wpisÃ³w do usuniÄ™cia')
    }

    // PrzetwÃ³rz chunki i zapisz do bazy
    let processedCount = 0
    const batchSize = 3 // Zmniejszona batch size

    for (let i = 0; i < chunks.length; i += batchSize) {
      const batch = chunks.slice(i, Math.min(i + batchSize, chunks.length))

      try {
        // UtwÃ³rz embeddingi dla batcha
        console.log(`ğŸ”„ Tworzenie embeddings dla chunkÃ³w ${i + 1}-${i + batch.length}...`)
        const embeddings: number[][] = []

        for (const chunk of batch) {
          const embedding = await createEmbedding(chunk)
          embeddings.push(embedding)
        }

        console.log(`ğŸ“Š Utworzono ${embeddings.length} embeddings`)

        // Przygotuj dane do zapisu
        const documents = batch.map((chunk, idx) => {
          const embeddingArray = embeddings[idx]
          console.log(`ğŸ” Embedding ${idx}: dÅ‚ugoÅ›Ä‡=${embeddingArray.length}, typ=${typeof embeddingArray}`)

          return {
            manual_name: manualName,
            content: chunk,
            page_number: Math.floor((i + idx) / (chunks.length / 100)),
            embedding: embeddingArray, // âœ… Tablica liczb - Supabase automatycznie konwertuje na vector
            metadata: {
              chunk_index: i + idx,
              total_chunks: chunks.length,
            },
          }
        })

        // Zapisz do Supabase
        const { error } = await supabase
          .from('manuals_documents')
          .insert(documents)

        if (error) {
          console.error('âŒ BÅ‚Ä…d zapisu do Supabase:', error)
          throw new Error(`Supabase error: ${error.message}`)
        }

        processedCount += batch.length
        console.log(`âœ… Zapisano ${processedCount}/${chunks.length} chunkÃ³w`)
      } catch (batchError: any) {
        console.error(`âŒ BÅ‚Ä…d w batchu ${i}-${i + batch.length}:`, batchError)
        throw batchError
      }
    }

    return NextResponse.json({
      success: true,
      message: `Manual ${manualName} zostaÅ‚ pomyÅ›lnie przetworzony`,
      stats: {
        totalChunks: chunks.length,
        manualName,
        textLength: manualText.length,
      },
    })
  } catch (error: any) {
    console.error('BÅ‚Ä…d przetwarzania manuala:', error)
    return NextResponse.json(
      { error: error.message || 'BÅ‚Ä…d przetwarzania tekstu' },
      { status: 500 }
    )
  }
}
